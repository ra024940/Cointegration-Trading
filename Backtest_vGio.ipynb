{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                               # panda\n",
    "import pandas_datareader as pdr                   # Baixar dados yahoo\n",
    "\n",
    "import matplotlib.pyplot as plt                   # grafico\n",
    "import matplotlib.dates as mdates                 # trabalhar datas\n",
    "\n",
    "import statsmodels.api as sm                      # regressao\n",
    "from statsmodels.api import add_constant          # para a regressao considerar o intercepto\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "#import seaborn as sns\n",
    "\n",
    "from statsmodels.tsa.stattools import coint       # Funcao Coint ()\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Declaracoes\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "#!pip install MetaTrader5\n",
    "#!pip install --upgrade MetaTrader5\n",
    "import MetaTrader5 as mt5\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import time\n",
    "import pytz\n",
    "\n",
    "import ipywidgets\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_data(tickers,inicio,fim,janela):\n",
    "\n",
    "    # Checa se ja estamos conectados, se não, conecta\n",
    "    if (mt5.terminal_info()==None):\n",
    "          \n",
    "        # conecte-se ao MetaTrader 5\n",
    "        if not mt5.initialize():\n",
    "            print(\"initialize() failed, error code =\",mt5.last_error())\n",
    "            mt5.shutdown()\n",
    "        \n",
    "    #quebra as strings dates(inicio,fim) recebidas e transformando em integer\n",
    "    inicio_= inicio.split('-')\n",
    "    inicio = [int(element) for element in inicio_]\n",
    "    fim_= fim.split('-')\n",
    "    fim = [int(element) for element in fim_]\n",
    "\n",
    "    timezone = pytz.timezone(\"Etc/UTC\")\n",
    "    \n",
    "    #Verifica caso seja timeframe diario ou intraday\n",
    "    if janela == '1d':\n",
    "        dt_inicio = datetime(inicio[0], inicio[1], inicio[2], tzinfo=timezone)\n",
    "        dt_fim = datetime(fim[0], fim[1], fim[2], tzinfo=timezone)\n",
    "        timeframe = mt5.TIMEFRAME_D1\n",
    "    #aqui trata as datas intraday\n",
    "    else:\n",
    "        dt_inicio = datetime(inicio[0], inicio[1], inicio[2], inicio[3], inicio[4], tzinfo=timezone)\n",
    "        dt_fim = datetime(fim[0], fim[1], fim[2], fim[3], fim[4], tzinfo=timezone)\n",
    "        timeframe = mt5.TIMEFRAME_M15\n",
    "        \n",
    "    # obtendo o par de acoes com base nas datas enviadas nas strings, caso len seja 1, getdata retorna o dataframe de uma unica acao\n",
    "    if (len (tickers) == 1):        \n",
    "        stock1 = mt5.copy_rates_range(tickers[0], timeframe, dt_inicio, dt_fim)    \n",
    "        stock_df = pd.DataFrame(stock1)[['close','time']].rename(columns={'close': tickers[0]})\n",
    "                \n",
    "    else:    \n",
    "        stock1 = mt5.copy_rates_range(tickers[0], timeframe, dt_inicio, dt_fim)\n",
    "        stock2 = mt5.copy_rates_range(tickers[1], timeframe, dt_inicio, dt_fim)\n",
    "        esquerda = pd.DataFrame(stock1)[['close','time']].rename(columns={'close': tickers[0]})\n",
    "        direita = pd.DataFrame(stock2)[['close','time']].rename(columns={'close': tickers[1]})\n",
    "        stock_df = pd.merge(left=esquerda, right=direita, left_on='time', right_on='time')\n",
    "    \n",
    "    #Se o timeframe for intraday, retorna um datetime (com minutos e horas), caso contrario, retorna um date\n",
    "    if (janela != '1d'):\n",
    "        stock_df['Date'] = stock_df['time'].apply(lambda x: str (datetime.fromtimestamp(x, tz=timezone))[:-9]) #define timezone\n",
    "    else:\n",
    "        stock_df['Date'] = stock_df['time'].apply(lambda x: date.fromtimestamp(x+21600)) #adicionando 21600 pra corrigir o fuso no momento de converter tsp em str\n",
    "        stock_df.drop('time',axis=1,inplace = True)\n",
    "        \n",
    "    return stock_df.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera a REGRESSAO LINEAR MULTIVARIADA (QuantGo \"Simples\") -> y = b*x + c*t + d + e\n",
    "def regressao_multivariada(x, y, periodo):  \n",
    "    \n",
    "    X = np.column_stack((x, range(1,periodo+1,1)))\n",
    "    X = sm.add_constant(X)\n",
    "    res = sm.OLS(y,X).fit()\n",
    "    coef_ang=res.params[1]\n",
    "    residuo = y-res.predict()\n",
    "    zscore  = (residuo - np.mean(residuo))/np.std(residuo);\n",
    "    return coef_ang, residuo, zscore, res\n",
    "\n",
    "\n",
    "def regressao_residuos(residuos):\n",
    "  \n",
    "    residuos_shifted = residuos.diff(1).fillna(method=\"bfill\")  \n",
    "    delta = residuos - residuos_shifted\n",
    "    X = sm.add_constant(residuos_shifted, prepend=True)\n",
    "    res = sm.OLS(residuos,X).fit()\n",
    "    return res.params[1]\n",
    "\n",
    "# ADF da Statsmodel e teste de significancia com os critical values do Ferro\n",
    "def adftest(df,reg):\n",
    "\n",
    "    adf  = adfuller(df,maxlag=1, autolag=\"BIC\")\n",
    "    \n",
    "    adf_stat = adf[0]\n",
    "    adf_pvalue = adf[1]\n",
    "    \n",
    "    ## %ADF clássico, de acordo com o output da função  - NAO UTILIZADO\n",
    "    if   adf[0] < adf[4]['1%']:  adfc='99%'\n",
    "    elif adf[0] < adf[4]['5%']:  adfc='95%'\n",
    "    elif adf[0] < adf[4]['10%']: adfc='90%'\n",
    "    else:                        adfc='-'                 \n",
    "\n",
    "    ## %ADF do Ferro\n",
    "    # Utiliza duas tabelas - uma para quando o tempo é significante, outra quando não é (indep. do noobs)\n",
    "    ttest = reg.params[1]/reg.bse[1]\n",
    "    critical_value_tempo = scipy.stats.t.ppf(0.01,df=(len(df)-3)) # Retorna o inverso bicaudal da distribuição t de Student\n",
    "\n",
    "    if (abs(ttest) < critical_value_tempo): aceitar_t0 = '99%'\n",
    "    else:  aceitar_t0 = '0%'\n",
    "    \n",
    "    if (aceitar_t0 == '0%'):\n",
    "        if   adf[0] < -4.32:         adf_sign='99%'\n",
    "        elif adf[0] < -3.67:         adf_sign='95%'\n",
    "        elif adf[0] < -3.28:         adf_sign='90%'\n",
    "        else:                        adf_sign='-' \n",
    "    else:    \n",
    "        if   adf[0] < -3.58:         adf_sign='99%'\n",
    "        elif adf[0] < -3.22:         adf_sign='95%'\n",
    "        elif adf[0] < -2.60:         adf_sign='90%'\n",
    "        else:                        adf_sign='-'                 \n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "    return adf_stat, adf_sign, adf_pvalue  \n",
    "\n",
    "\n",
    "def pearsonr_ci(x,y,alpha=0.05):\n",
    "    ''' calculate Pearson correlation along with the confidence interval using scipy and numpy Parameters\n",
    "    ----------\n",
    "    x, y : iterable object such as a list or np.array\n",
    "      Input for correlation calculation\n",
    "    alpha : float\n",
    "      Significance level. 0.05 by default\n",
    "    Returns\n",
    "    -------\n",
    "    r : float\n",
    "      Pearson's correlation coefficient\n",
    "    pval : float\n",
    "      The corresponding p value\n",
    "    lo, hi : float\n",
    "      The lower and upper bound of confidence intervals\n",
    "    '''\n",
    "    \n",
    "    r, p = scipy.stats.pearsonr(x,y)\n",
    "    r_z = np.arctanh(r)\n",
    "    se = 1/np.sqrt(x.size-3)\n",
    "    z = scipy.stats.norm.ppf(1-alpha/2)\n",
    "    lo_z, hi_z = r_z-z*se, r_z+z*se\n",
    "    lo, hi = np.tanh((lo_z, hi_z))\n",
    "    \n",
    "    return r, p, lo, hi\n",
    "    \n",
    "def pct_financeiro(x,y,coef_ang,residuo):\n",
    "    \n",
    "    ultimo_x = float(x.tail(1))\n",
    "    ultimo_y = float(y.tail(1))\n",
    "    \n",
    "    fin_x = ultimo_x*coef_ang\n",
    "    fin_y = ultimo_y\n",
    "    \n",
    "    if (residuo > 0):\n",
    "        compra = fin_x\n",
    "        venda = fin_y\n",
    "    else:\n",
    "        compra = fin_y\n",
    "        venda = fin_x\n",
    " \n",
    "    cv = \"{:.0%}\".format(compra/venda)\n",
    "    return cv\n",
    "\n",
    "\n",
    "def calculo_meia_vida1(residuo):\n",
    "    # Retirado de um paper e adaptado pela formula da planilha do Ferro\n",
    "    price = pd.Series(residuo)  \n",
    "    lagged_price = price.shift(1).fillna(method=\"bfill\")  \n",
    "    delta = price - lagged_price  \n",
    "    beta = np.polyfit(lagged_price, delta, 1)[0] \n",
    "    #half_life = ((-2*np.log(2))/beta)  # paper (varios), mas sem o 2*\n",
    "    half_life = 2/(-1*np.log(1+beta))   # planilha ferro\n",
    "     \n",
    "    return (int(round(half_life)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajusta_B3Date (data_start, qtde_dias):\n",
    "    \n",
    "    df = pd.read_excel('Calendar.xlsx')\n",
    "    df['Date'] = df['Date'].apply(str)\n",
    "    index = df [df['Date'] == data_start].index.values.astype(int)[0]\n",
    "    data_fim = df.iloc[index+qtde_dias][1]\n",
    "    \n",
    "    return (data_fim + '-17-00')\n",
    "\n",
    "    \n",
    "def simula_trade (ticker, beta_inicio, dp_entrada, dp_target, start_time , hlife):\n",
    "    \n",
    "    #passando a data de inicio do trade para identificarmos qual a data limite para o trade com base no calendario da B3\n",
    "    end_time = ajusta_B3Date(start_time[:-6],hlife)\n",
    "    #print (start_time)\n",
    "    #print (end_time)\n",
    "    stock = Get_data(ticker, start_time, end_time,'M5')\n",
    "    \n",
    "    return stock\n",
    "    \n",
    "def merge_intraday (ticker, dt_inicio, dt_intraday):\n",
    "\n",
    "    dt_temp = dt_intraday.split('-')\n",
    "    dt_temp = [int(element) for element in dt_temp]\n",
    "    dt_temp[2] = dt_temp[2] - 1\n",
    "    dt_fim = str(dt_temp[0])+'-0'+str(dt_temp[1])+'-'+str(dt_temp[2])\n",
    "    stock  = Get_data(ticker, dt_inicio,dt_fim,'1d')\n",
    "    stock_intraday = Get_data(ticker, dt_intraday,dt_intraday,'M5')\n",
    "    stock_intraday['Date'] =  stock_intraday['time'].apply(date.fromtimestamp)\n",
    "    stock_intraday.set_index('Date', inplace = True)\n",
    "    stock_concat = pd.concat([stock,stock_intraday])\n",
    "    stock_concat.drop('time',axis=1,inplace = True)\n",
    "\n",
    "    return stock_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Cubo (tickers, dt_cubo, intra_bt):\n",
    "    \n",
    "    #Pegando a data B3 de 250 regoes atras\n",
    "    if intra_bt:\n",
    "        dt_inicio = ajusta_B3Date(dt_cubo[:-6],-250)\n",
    "    else:\n",
    "        dt_inicio = ajusta_B3Date(dt_cubo,-250)\n",
    "    \n",
    "    #print (dt_inicio)\n",
    "    \n",
    "    if intra_bt:\n",
    "        #Para retornar o par com dados diarios, com ultimo dia sendo o intraday passado em dt_final\n",
    "        par = merge_intraday (tickers, dt_inicio, dt_cubo)\n",
    "    else:   \n",
    "        # Busca cotacoes no Yahoo Finance\n",
    "        par = Get_data(tickers, dt_inicio, dt_cubo,'1d')\n",
    "\n",
    "    par['ratio']  = par[tickers[0]]/par[tickers[1]]\n",
    "    par['ratio1'] = par[tickers[1]]/par[tickers[0]]\n",
    "\n",
    "    # Cria o cubo de periodos\n",
    "    cubo = pd.DataFrame(columns=['periodo','ratio','adf_stat','adf_sign','coef_Ang',\n",
    "                                 'desvio','pct_fin','meia_vida', 'corr'])\n",
    "\n",
    "    # Popula o cubo de periodos\n",
    "    #for i in range(100,260,10):\n",
    "    for i in [100,120,140,160,180,200,220,240,250]:\n",
    "\n",
    "        # Cria subset do tamanho do periodo atual da iteração e seta a variavel indep (x) e dependente (y)\n",
    "        par_subset = par.tail(i)\n",
    "        x = par_subset[tickers[1]]\n",
    "        y = par_subset[tickers[0]]\n",
    "\n",
    "        # Adiciona o PERIODO analisado no dataframe\n",
    "        cubo = cubo.append({'periodo': int(i)}, ignore_index=True)\n",
    "        # Gera a REGRESSAO e retorna o Coef Ang, os residuos e o z-score. \n",
    "        # Retorna tbm o vetor de retorno da regressao para ser usado no ADF\n",
    "        coef_ang, residuo, zscore, reg  = regressao_multivariada(x, y, i)\n",
    "\n",
    "        # Teste de Estacionariedade dos Resíduos (ADF)\n",
    "        adf_stat,adf_sign,adf_pvalue = adftest(residuo, reg)\n",
    "         \n",
    "        # Calculo do Fisher\n",
    "        fisher_r, fisher_pvalue, fisher_lo, fisher_hi = pearsonr_ci(x.diff().fillna(method=\"bfill\"), y.diff().fillna(method=\"bfill\"))\n",
    "\n",
    "        # Calculo do % Financeiro (C/V)\n",
    "        pct_fin = pct_financeiro(x,y,coef_ang, float(zscore.tail(1)))\n",
    "\n",
    "        # Calculo da Meia-vida - ORNSTEIN-UHLENBECK\n",
    "        meia_vida = calculo_meia_vida1(residuo)\n",
    "\n",
    "        # Correlação \n",
    "        corr = np.corrcoef(x.pct_change().cumsum().dropna(), y.pct_change().cumsum().dropna())[1,0]\n",
    "\n",
    "        # Se fisher minimo menor que 10%, ou se correlacao < 0, faz adf_sign=0%\n",
    "        if ((fisher_lo <= 0.1) or (corr<=0)):\n",
    "            adf_sign = \"0%\"\n",
    "            \n",
    "        # Preenchimento do cubo\n",
    "        cubo.loc[ (cubo['periodo']==i), 'ratio'      ] = float(y.tail(1))/float(x.tail(1))\n",
    "        cubo.loc[ (cubo['periodo']==i), 'coef_Ang'   ] = coef_ang \n",
    "        cubo.loc[ (cubo['periodo']==i), 'desvio'     ] = float(zscore.tail(1))\n",
    "        cubo.loc[ (cubo['periodo']==i), 'adf_stat'   ] = adf_stat\n",
    "        cubo.loc[ (cubo['periodo']==i), 'adf_sign'   ] = adf_sign \n",
    "        cubo.loc[ (cubo['periodo']==i), 'pct_fin'    ] = pct_fin\n",
    "        cubo.loc[ (cubo['periodo']==i), 'meia_vida'  ] = meia_vida\n",
    "        cubo.loc[ (cubo['periodo']==i), 'corr'       ] = corr\n",
    "\n",
    "\n",
    "    #par.to_excel(\"Par.xlsx\")    \n",
    "    #display(cubo)\n",
    "\n",
    "\n",
    "    \n",
    "    return cubo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['ITUB4','BBSE3']\n",
    "a = Get_Cubo(tickers,'2020-08-10',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-02-10-00\n",
      "2018-01-02-10-15\n",
      "2018-01-02-10-30\n",
      "2018-01-02-10-45\n",
      "2018-01-02-11-00\n",
      "2018-01-02-11-15\n",
      "2018-01-02-11-30\n",
      "2018-01-02-11-45\n",
      "2018-01-02-12-00\n",
      "2018-01-02-12-15\n",
      "2018-01-02-12-30\n",
      "2018-01-02-12-45\n",
      "2018-01-02-13-00\n",
      "2018-01-02-13-15\n",
      "2018-01-02-13-30\n",
      "2018-01-02-13-45\n",
      "2018-01-02-14-00\n",
      "2018-01-02-14-15\n",
      "2018-01-02-14-30\n",
      "2018-01-02-14-45\n",
      "2018-01-02-15-00\n",
      "2018-01-02-15-15\n",
      "2018-01-02-15-30\n",
      "2018-01-02-15-45\n",
      "2018-01-02-16-00\n",
      "2018-01-02-16-15\n",
      "2018-01-02-16-30\n",
      "2018-01-02-16-45\n",
      "2018-01-02-17-00\n",
      "2018-01-02-17-15\n",
      "2018-01-02-17-30\n",
      "2018-01-02-17-45\n",
      "2018-01-03-10-00\n",
      "2018-01-03-10-15\n",
      "2018-01-03-10-30\n",
      "2018-01-03-10-45\n",
      "2018-01-03-11-00\n",
      "2018-01-03-11-15\n",
      "2018-01-03-11-30\n",
      "2018-01-03-11-45\n",
      "2018-01-03-12-00\n",
      "2018-01-03-12-15\n",
      "2018-01-03-12-30\n",
      "2018-01-03-12-45\n",
      "2018-01-03-13-00\n",
      "2018-01-03-13-15\n",
      "2018-01-03-13-30\n",
      "2018-01-03-13-45\n",
      "2018-01-03-14-00\n",
      "2018-01-03-14-15\n",
      "2018-01-03-14-30\n",
      "2018-01-03-14-45\n",
      "2018-01-03-15-00\n",
      "2018-01-03-15-15\n",
      "2018-01-03-15-30\n",
      "2018-01-03-15-45\n",
      "2018-01-03-16-00\n",
      "2018-01-03-16-15\n",
      "2018-01-03-16-30\n",
      "2018-01-03-16-45\n",
      "2018-01-03-17-00\n",
      "2018-01-03-17-15\n",
      "2018-01-03-17-30\n",
      "2018-01-03-17-45\n",
      "2018-01-03-18-00\n",
      "2018-01-04-10-00\n",
      "2018-01-04-10-15\n",
      "2018-01-04-10-30\n",
      "2018-01-04-10-45\n",
      "2018-01-04-11-00\n",
      "2018-01-04-11-15\n",
      "2018-01-04-11-30\n",
      "2018-01-04-11-45\n",
      "2018-01-04-12-00\n",
      "2018-01-04-12-15\n",
      "2018-01-04-12-30\n",
      "2018-01-04-12-45\n",
      "2018-01-04-13-00\n",
      "2018-01-04-13-15\n",
      "2018-01-04-13-30\n",
      "2018-01-04-13-45\n",
      "2018-01-04-14-00\n",
      "2018-01-04-14-15\n",
      "2018-01-04-14-30\n",
      "2018-01-04-14-45\n",
      "2018-01-04-15-00\n",
      "2018-01-04-15-15\n",
      "2018-01-04-15-30\n",
      "2018-01-04-15-45\n",
      "2018-01-04-16-00\n",
      "2018-01-04-16-15\n",
      "2018-01-04-16-30\n",
      "2018-01-04-16-45\n",
      "2018-01-04-17-00\n",
      "2018-01-04-17-15\n",
      "2018-01-04-17-30\n",
      "2018-01-04-17-45\n",
      "2018-01-05-10-00\n",
      "2018-01-05-10-15\n",
      "2018-01-05-10-30\n",
      "2018-01-05-10-45\n",
      "2018-01-05-11-00\n",
      "2018-01-05-11-15\n",
      "2018-01-05-11-30\n",
      "2018-01-05-11-45\n",
      "2018-01-05-12-00\n",
      "2018-01-05-12-15\n",
      "2018-01-05-12-30\n",
      "2018-01-05-12-45\n",
      "2018-01-05-13-00\n",
      "2018-01-05-13-15\n",
      "2018-01-05-13-30\n",
      "2018-01-05-13-45\n",
      "2018-01-05-14-00\n",
      "2018-01-05-14-15\n",
      "2018-01-05-14-30\n",
      "2018-01-05-14-45\n",
      "2018-01-05-15-00\n",
      "2018-01-05-15-15\n",
      "2018-01-05-15-30\n",
      "2018-01-05-15-45\n",
      "2018-01-05-16-00\n",
      "2018-01-05-16-15\n",
      "2018-01-05-16-30\n",
      "2018-01-05-16-45\n",
      "2018-01-05-17-00\n",
      "2018-01-05-17-15\n",
      "2018-01-05-17-30\n",
      "2018-01-05-17-45\n",
      "2018-01-08-10-00\n",
      "2018-01-08-10-15\n",
      "2018-01-08-10-30\n",
      "2018-01-08-10-45\n",
      "2018-01-08-11-00\n",
      "2018-01-08-11-15\n",
      "2018-01-08-11-30\n",
      "2018-01-08-11-45\n",
      "2018-01-08-12-00\n",
      "2018-01-08-12-15\n",
      "2018-01-08-12-30\n",
      "2018-01-08-12-45\n",
      "2018-01-08-13-00\n",
      "2018-01-08-13-15\n",
      "2018-01-08-13-30\n",
      "2018-01-08-13-45\n",
      "2018-01-08-14-00\n",
      "2018-01-08-14-15\n",
      "2018-01-08-14-30\n",
      "2018-01-08-14-45\n",
      "2018-01-08-15-00\n",
      "2018-01-08-15-15\n",
      "2018-01-08-15-30\n",
      "2018-01-08-15-45\n",
      "2018-01-08-16-00\n",
      "2018-01-08-16-15\n",
      "2018-01-08-16-30\n",
      "2018-01-08-16-45\n",
      "2018-01-08-17-00\n",
      "2018-01-08-17-15\n",
      "2018-01-08-17-30\n",
      "2018-01-08-17-45\n",
      "2018-01-09-10-00\n",
      "2018-01-09-10-15\n",
      "2018-01-09-10-30\n",
      "2018-01-09-10-45\n",
      "2018-01-09-11-00\n",
      "2018-01-09-11-15\n",
      "2018-01-09-11-30\n",
      "2018-01-09-11-45\n",
      "2018-01-09-12-00\n",
      "2018-01-09-12-15\n",
      "2018-01-09-12-30\n",
      "2018-01-09-12-45\n",
      "2018-01-09-13-00\n",
      "2018-01-09-13-15\n",
      "2018-01-09-13-30\n",
      "2018-01-09-13-45\n",
      "2018-01-09-14-00\n",
      "2018-01-09-14-15\n",
      "2018-01-09-14-30\n",
      "2018-01-09-14-45\n",
      "2018-01-09-15-00\n",
      "2018-01-09-15-15\n",
      "2018-01-09-15-30\n",
      "2018-01-09-15-45\n",
      "2018-01-09-16-00\n",
      "2018-01-09-16-15\n",
      "2018-01-09-16-30\n",
      "2018-01-09-16-45\n",
      "2018-01-09-17-00\n",
      "2018-01-09-17-15\n",
      "2018-01-09-17-30\n",
      "2018-01-09-17-45\n",
      "2018-01-10-10-00\n",
      "2018-01-10-10-15\n",
      "2018-01-10-10-30\n",
      "2018-01-10-10-45\n",
      "2018-01-10-11-00\n",
      "2018-01-10-11-15\n",
      "2018-01-10-11-30\n",
      "2018-01-10-11-45\n",
      "2018-01-10-12-00\n",
      "2018-01-10-12-15\n",
      "2018-01-10-12-30\n",
      "2018-01-10-12-45\n",
      "2018-01-10-13-00\n",
      "2018-01-10-13-15\n",
      "2018-01-10-13-30\n",
      "2018-01-10-13-45\n",
      "2018-01-10-14-00\n",
      "2018-01-10-14-15\n",
      "2018-01-10-14-30\n",
      "2018-01-10-14-45\n",
      "2018-01-10-15-00\n",
      "2018-01-10-15-15\n",
      "2018-01-10-15-30\n",
      "2018-01-10-15-45\n",
      "2018-01-10-16-00\n",
      "2018-01-10-16-15\n",
      "2018-01-10-16-30\n",
      "2018-01-10-16-45\n",
      "2018-01-10-17-00\n",
      "2018-01-10-17-15\n",
      "2018-01-10-17-30\n",
      "2018-01-10-17-45\n",
      "2018-01-11-10-00\n",
      "2018-01-11-10-15\n",
      "2018-01-11-10-30\n",
      "2018-01-11-10-45\n",
      "2018-01-11-11-00\n",
      "2018-01-11-11-15\n",
      "2018-01-11-11-30\n",
      "2018-01-11-11-45\n",
      "2018-01-11-12-00\n",
      "2018-01-11-12-15\n",
      "2018-01-11-12-30\n",
      "2018-01-11-12-45\n",
      "2018-01-11-13-00\n",
      "2018-01-11-13-15\n",
      "2018-01-11-13-30\n",
      "2018-01-11-13-45\n",
      "2018-01-11-14-00\n",
      "2018-01-11-14-15\n",
      "2018-01-11-14-30\n",
      "2018-01-11-14-45\n",
      "2018-01-11-15-00\n",
      "2018-01-11-15-15\n",
      "2018-01-11-15-30\n",
      "2018-01-11-15-45\n",
      "2018-01-11-16-00\n",
      "2018-01-11-16-15\n",
      "2018-01-11-16-30\n",
      "2018-01-11-16-45\n",
      "2018-01-11-17-00\n",
      "2018-01-11-17-15\n",
      "2018-01-11-17-30\n",
      "2018-01-11-17-45\n",
      "2018-01-12-10-00\n",
      "2018-01-12-10-15\n",
      "2018-01-12-10-30\n",
      "2018-01-12-10-45\n",
      "2018-01-12-11-00\n",
      "2018-01-12-11-15\n",
      "2018-01-12-11-30\n",
      "2018-01-12-11-45\n",
      "2018-01-12-12-00\n",
      "2018-01-12-12-15\n",
      "2018-01-12-12-30\n",
      "2018-01-12-12-45\n",
      "2018-01-12-13-00\n",
      "2018-01-12-13-15\n",
      "2018-01-12-13-30\n",
      "2018-01-12-13-45\n",
      "2018-01-12-14-00\n",
      "2018-01-12-14-15\n",
      "2018-01-12-14-30\n",
      "2018-01-12-14-45\n",
      "2018-01-12-15-00\n",
      "2018-01-12-15-15\n",
      "2018-01-12-15-30\n",
      "2018-01-12-15-45\n",
      "2018-01-12-16-00\n",
      "2018-01-12-16-15\n",
      "2018-01-12-16-30\n",
      "2018-01-12-16-45\n",
      "2018-01-12-17-00\n",
      "2018-01-12-17-15\n",
      "2018-01-12-17-30\n",
      "2018-01-12-17-45\n",
      "2018-01-15-10-00\n",
      "2018-01-15-10-15\n",
      "2018-01-15-10-30\n",
      "2018-01-15-10-45\n",
      "2018-01-15-11-00\n",
      "2018-01-15-11-15\n",
      "2018-01-15-11-30\n",
      "2018-01-15-11-45\n",
      "2018-01-15-12-00\n",
      "2018-01-15-12-15\n",
      "2018-01-15-12-30\n",
      "2018-01-15-12-45\n",
      "2018-01-15-13-00\n",
      "2018-01-15-13-15\n",
      "2018-01-15-13-30\n",
      "2018-01-15-13-45\n",
      "2018-01-15-14-00\n",
      "2018-01-15-14-15\n",
      "2018-01-15-14-30\n",
      "2018-01-15-14-45\n",
      "2018-01-15-15-00\n",
      "2018-01-15-15-15\n",
      "2018-01-15-15-30\n",
      "2018-01-15-15-45\n",
      "2018-01-15-16-00\n",
      "2018-01-15-16-15\n",
      "2018-01-15-16-30\n",
      "2018-01-15-16-45\n",
      "2018-01-15-17-00\n",
      "2018-01-15-17-15\n",
      "2018-01-15-17-30\n",
      "2018-01-15-17-45\n",
      "2018-01-16-10-00\n",
      "2018-01-16-10-15\n",
      "2018-01-16-10-30\n",
      "2018-01-16-10-45\n",
      "2018-01-16-11-00\n",
      "2018-01-16-11-15\n",
      "2018-01-16-11-30\n",
      "2018-01-16-11-45\n",
      "2018-01-16-12-00\n",
      "2018-01-16-12-15\n",
      "2018-01-16-12-30\n",
      "2018-01-16-12-45\n",
      "2018-01-16-13-00\n",
      "2018-01-16-13-15\n",
      "2018-01-16-13-30\n",
      "2018-01-16-13-45\n",
      "2018-01-16-14-00\n",
      "2018-01-16-14-15\n",
      "2018-01-16-14-30\n",
      "2018-01-16-14-45\n",
      "2018-01-16-15-00\n",
      "2018-01-16-15-15\n",
      "2018-01-16-15-30\n",
      "2018-01-16-15-45\n",
      "2018-01-16-16-00\n",
      "2018-01-16-16-15\n",
      "2018-01-16-16-30\n",
      "2018-01-16-16-45\n",
      "2018-01-16-17-00\n",
      "2018-01-16-17-15\n",
      "2018-01-16-17-30\n",
      "2018-01-16-17-45\n",
      "2018-01-17-10-00\n",
      "2018-01-17-10-15\n",
      "2018-01-17-10-30\n",
      "2018-01-17-10-45\n",
      "2018-01-17-11-00\n",
      "2018-01-17-11-15\n",
      "2018-01-17-11-30\n",
      "2018-01-17-11-45\n",
      "2018-01-17-12-00\n",
      "2018-01-17-12-15\n",
      "2018-01-17-12-30\n",
      "2018-01-17-12-45\n",
      "2018-01-17-13-00\n",
      "2018-01-17-13-15\n",
      "2018-01-17-13-30\n",
      "2018-01-17-13-45\n",
      "2018-01-17-14-00\n",
      "2018-01-17-14-15\n",
      "2018-01-17-14-30\n",
      "2018-01-17-14-45\n",
      "2018-01-17-15-00\n",
      "2018-01-17-15-15\n",
      "2018-01-17-15-30\n",
      "2018-01-17-15-45\n",
      "2018-01-17-16-00\n",
      "2018-01-17-16-15\n",
      "2018-01-17-16-30\n",
      "2018-01-17-16-45\n",
      "2018-01-17-17-00\n",
      "2018-01-17-17-15\n",
      "2018-01-17-17-30\n",
      "2018-01-17-17-45\n",
      "2018-01-18-10-00\n",
      "2018-01-18-10-15\n",
      "2018-01-18-10-30\n",
      "2018-01-18-10-45\n",
      "2018-01-18-11-00\n",
      "2018-01-18-11-15\n",
      "2018-01-18-11-30\n",
      "2018-01-18-11-45\n",
      "2018-01-18-12-00\n",
      "2018-01-18-12-15\n",
      "2018-01-18-12-30\n",
      "2018-01-18-12-45\n",
      "2018-01-18-13-00\n",
      "2018-01-18-13-15\n",
      "2018-01-18-13-30\n",
      "2018-01-18-13-45\n",
      "2018-01-18-14-00\n",
      "2018-01-18-14-15\n",
      "2018-01-18-14-30\n",
      "2018-01-18-14-45\n",
      "2018-01-18-15-00\n",
      "2018-01-18-15-15\n",
      "2018-01-18-15-30\n",
      "2018-01-18-15-45\n",
      "2018-01-18-16-00\n",
      "2018-01-18-16-15\n",
      "2018-01-18-16-30\n",
      "2018-01-18-16-45\n",
      "2018-01-18-17-00\n",
      "2018-01-18-17-15\n",
      "2018-01-18-17-30\n",
      "2018-01-18-17-45\n",
      "2018-01-19-10-00\n",
      "2018-01-19-10-15\n",
      "2018-01-19-10-30\n",
      "2018-01-19-10-45\n",
      "2018-01-19-11-00\n",
      "2018-01-19-11-15\n",
      "2018-01-19-11-30\n",
      "2018-01-19-11-45\n",
      "2018-01-19-12-00\n",
      "2018-01-19-12-15\n",
      "2018-01-19-12-30\n",
      "2018-01-19-12-45\n",
      "2018-01-19-13-00\n",
      "2018-01-19-13-15\n",
      "2018-01-19-13-30\n",
      "2018-01-19-13-45\n",
      "2018-01-19-14-00\n",
      "2018-01-19-14-15\n",
      "2018-01-19-14-30\n",
      "2018-01-19-14-45\n",
      "2018-01-19-15-00\n",
      "2018-01-19-15-15\n",
      "2018-01-19-15-30\n",
      "2018-01-19-15-45\n",
      "2018-01-19-16-00\n",
      "2018-01-19-16-15\n",
      "2018-01-19-16-30\n",
      "2018-01-19-16-45\n",
      "2018-01-19-17-00\n",
      "2018-01-19-17-15\n",
      "2018-01-19-17-30\n",
      "2018-01-19-17-45\n",
      "2018-01-22-10-00\n",
      "2018-01-22-10-15\n",
      "2018-01-22-10-30\n",
      "2018-01-22-10-45\n",
      "2018-01-22-11-00\n",
      "2018-01-22-11-15\n",
      "2018-01-22-11-30\n",
      "2018-01-22-11-45\n",
      "2018-01-22-12-00\n",
      "2018-01-22-12-15\n",
      "2018-01-22-12-30\n",
      "2018-01-22-12-45\n",
      "2018-01-22-13-00\n",
      "2018-01-22-13-15\n",
      "2018-01-22-13-30\n",
      "2018-01-22-13-45\n",
      "2018-01-22-14-00\n",
      "2018-01-22-14-15\n",
      "2018-01-22-14-30\n",
      "2018-01-22-14-45\n",
      "2018-01-22-15-00\n",
      "2018-01-22-15-15\n",
      "2018-01-22-15-30\n",
      "2018-01-22-15-45\n",
      "2018-01-22-16-00\n",
      "2018-01-22-16-15\n",
      "2018-01-22-16-30\n",
      "2018-01-22-16-45\n",
      "2018-01-22-17-00\n",
      "2018-01-22-17-15\n",
      "2018-01-22-17-30\n",
      "2018-01-22-17-45\n",
      "2018-01-23-10-00\n",
      "2018-01-23-10-15\n",
      "2018-01-23-10-30\n",
      "2018-01-23-10-45\n",
      "2018-01-23-11-00\n",
      "2018-01-23-11-15\n",
      "2018-01-23-11-30\n",
      "2018-01-23-11-45\n",
      "2018-01-23-12-00\n",
      "2018-01-23-12-15\n",
      "2018-01-23-12-30\n",
      "2018-01-23-12-45\n",
      "2018-01-23-13-00\n",
      "2018-01-23-13-15\n",
      "2018-01-23-13-30\n",
      "2018-01-23-13-45\n",
      "2018-01-23-14-00\n",
      "2018-01-23-14-15\n",
      "2018-01-23-14-30\n",
      "2018-01-23-14-45\n",
      "2018-01-23-15-00\n",
      "2018-01-23-15-15\n",
      "2018-01-23-15-30\n",
      "2018-01-23-15-45\n",
      "2018-01-23-16-00\n",
      "2018-01-23-16-15\n",
      "2018-01-23-16-30\n",
      "2018-01-23-16-45\n",
      "2018-01-23-17-00\n",
      "2018-01-23-17-15\n",
      "2018-01-23-17-30\n",
      "2018-01-23-17-45\n",
      "2018-01-24-10-00\n",
      "2018-01-24-10-15\n",
      "2018-01-24-10-30\n",
      "2018-01-24-10-45\n",
      "2018-01-24-11-00\n",
      "2018-01-24-11-15\n",
      "2018-01-24-11-30\n",
      "2018-01-24-11-45\n",
      "2018-01-24-12-00\n",
      "2018-01-24-12-15\n",
      "2018-01-24-12-30\n",
      "2018-01-24-12-45\n",
      "2018-01-24-13-00\n",
      "2018-01-24-13-15\n",
      "2018-01-24-13-30\n",
      "2018-01-24-13-45\n",
      "2018-01-24-14-00\n",
      "2018-01-24-14-15\n",
      "2018-01-24-14-30\n",
      "2018-01-24-14-45\n",
      "2018-01-24-15-00\n",
      "2018-01-24-15-15\n",
      "2018-01-24-15-30\n",
      "2018-01-24-15-45\n",
      "2018-01-24-16-00\n",
      "2018-01-24-16-15\n",
      "2018-01-24-16-30\n",
      "2018-01-24-16-45\n",
      "2018-01-24-17-00\n",
      "2018-01-24-17-15\n",
      "2018-01-24-17-30\n",
      "2018-01-24-17-45\n",
      "2018-01-26-10-00\n",
      "2018-01-26-10-15\n",
      "2018-01-26-10-30\n",
      "2018-01-26-10-45\n",
      "2018-01-26-11-00\n",
      "2018-01-26-11-15\n",
      "2018-01-26-11-30\n",
      "2018-01-26-11-45\n",
      "2018-01-26-12-00\n",
      "2018-01-26-12-15\n",
      "2018-01-26-12-30\n",
      "2018-01-26-12-45\n",
      "2018-01-26-13-00\n",
      "2018-01-26-13-15\n",
      "2018-01-26-13-30\n",
      "2018-01-26-13-45\n",
      "2018-01-26-14-00\n",
      "2018-01-26-14-15\n",
      "2018-01-26-14-30\n",
      "2018-01-26-14-45\n",
      "2018-01-26-15-00\n",
      "2018-01-26-15-15\n",
      "2018-01-26-15-30\n",
      "2018-01-26-15-45\n",
      "2018-01-26-16-00\n",
      "2018-01-26-16-15\n",
      "2018-01-26-16-30\n",
      "2018-01-26-16-45\n",
      "2018-01-26-17-00\n",
      "2018-01-26-17-15\n",
      "2018-01-26-17-30\n",
      "2018-01-26-17-45\n",
      "2018-01-29-10-00\n",
      "2018-01-29-10-15\n",
      "2018-01-29-10-30\n",
      "2018-01-29-10-45\n",
      "2018-01-29-11-00\n",
      "2018-01-29-11-15\n",
      "2018-01-29-11-30\n",
      "2018-01-29-11-45\n",
      "2018-01-29-12-00\n",
      "2018-01-29-12-15\n",
      "2018-01-29-12-30\n",
      "2018-01-29-12-45\n",
      "2018-01-29-13-00\n",
      "2018-01-29-13-15\n",
      "2018-01-29-13-30\n",
      "2018-01-29-13-45\n",
      "2018-01-29-14-00\n",
      "2018-01-29-14-15\n",
      "2018-01-29-14-30\n",
      "2018-01-29-14-45\n",
      "2018-01-29-15-00\n",
      "2018-01-29-15-15\n",
      "2018-01-29-15-30\n",
      "2018-01-29-15-45\n",
      "2018-01-29-16-00\n",
      "2018-01-29-16-15\n",
      "2018-01-29-16-30\n",
      "2018-01-29-16-45\n",
      "2018-01-29-17-00\n",
      "2018-01-29-17-15\n",
      "2018-01-29-17-30\n",
      "2018-01-29-17-45\n",
      "2018-01-30-10-00\n",
      "2018-01-30-10-15\n",
      "2018-01-30-10-30\n",
      "2018-01-30-10-45\n",
      "2018-01-30-11-00\n",
      "2018-01-30-11-15\n",
      "2018-01-30-11-30\n",
      "2018-01-30-11-45\n",
      "2018-01-30-12-00\n",
      "2018-01-30-12-15\n",
      "2018-01-30-12-30\n",
      "2018-01-30-12-45\n",
      "2018-01-30-13-00\n",
      "2018-01-30-13-15\n",
      "2018-01-30-13-30\n",
      "2018-01-30-13-45\n",
      "2018-01-30-14-00\n",
      "2018-01-30-14-15\n",
      "2018-01-30-14-30\n",
      "2018-01-30-14-45\n",
      "2018-01-30-15-00\n",
      "2018-01-30-15-15\n",
      "2018-01-30-15-30\n",
      "2018-01-30-15-45\n",
      "2018-01-30-16-00\n",
      "2018-01-30-16-15\n",
      "2018-01-30-16-30\n",
      "2018-01-30-16-45\n",
      "2018-01-30-17-00\n",
      "2018-01-30-17-15\n",
      "2018-01-30-17-30\n",
      "2018-01-30-17-45\n",
      "2018-01-31-10-00\n",
      "2018-01-31-10-15\n",
      "2018-01-31-10-30\n",
      "2018-01-31-10-45\n",
      "2018-01-31-11-00\n",
      "2018-01-31-11-15\n",
      "2018-01-31-11-30\n",
      "2018-01-31-11-45\n",
      "2018-01-31-12-00\n",
      "2018-01-31-12-15\n",
      "2018-01-31-12-30\n",
      "2018-01-31-12-45\n",
      "2018-01-31-13-00\n",
      "2018-01-31-13-15\n",
      "2018-01-31-13-30\n",
      "2018-01-31-13-45\n",
      "2018-01-31-14-00\n",
      "2018-01-31-14-15\n",
      "2018-01-31-14-30\n",
      "2018-01-31-14-45\n",
      "2018-01-31-15-00\n",
      "2018-01-31-15-15\n",
      "2018-01-31-15-30\n",
      "2018-01-31-15-45\n",
      "2018-01-31-16-00\n",
      "2018-01-31-16-15\n",
      "2018-01-31-16-30\n",
      "2018-01-31-16-45\n",
      "2018-01-31-17-00\n",
      "2018-01-31-17-15\n",
      "2018-01-31-17-30\n",
      "2018-01-31-17-45\n",
      "2018-02-01-10-00\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "day is out of range for month",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-45dbed785cdd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mdthora2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdthora1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"-\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mdthora1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdthora2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGet_Cubo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtickers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdthora2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[0mtmp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdthora2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mcubo_intraday\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcubo_intraday\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-99-47a2e66a4254>\u001b[0m in \u001b[0;36mGet_Cubo\u001b[1;34m(tickers, dt_cubo, intra_bt)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mintra_bt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m#Para retornar o par com dados diarios, com ultimo dia sendo o intraday passado em dt_final\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mpar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerge_intraday\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtickers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt_inicio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt_cubo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m# Busca cotacoes no Yahoo Finance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-50-d321b25b9038>\u001b[0m in \u001b[0;36mmerge_intraday\u001b[1;34m(ticker, dt_inicio, dt_intraday)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mdt_temp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt_temp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mdt_fim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt_temp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'-0'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt_temp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt_temp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mstock\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mGet_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt_inicio\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdt_fim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'1d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[0mstock_intraday\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGet_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt_intraday\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdt_intraday\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'M5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mstock_intraday\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mstock_intraday\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromtimestamp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-48-73e323584f0e>\u001b[0m in \u001b[0;36mGet_data\u001b[1;34m(tickers, inicio, fim, janela)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mjanela\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'1d'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mdt_inicio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minicio\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minicio\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minicio\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtzinfo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimezone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mdt_fim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtzinfo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimezone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mtimeframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmt5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTIMEFRAME_D1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m#aqui trata as datas intraday\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: day is out of range for month"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Cubo de fechamentos\n",
    "datas = Get_data(tickers,'2018-01-01','2020-08-10','1d').reset_index()['Date']\n",
    "\n",
    "tmp = pd.DataFrame()\n",
    "# cubo_fechamentos = pd.DataFrame(columns=['data','periodo','ratio','adf_stat','adf_sign','coef_Ang',\n",
    "#                                          'desvio','pct_fin','meia_vida', 'corr'])\n",
    "\n",
    "# for dat in datas:\n",
    "#     tmp = Get_Cubo(tickers,str(dat),False)\n",
    "#     tmp['data']=str(dat)\n",
    "#     cubo_fechamentos = cubo_fechamentos.append(tmp)\n",
    "\n",
    "# print(cubo_fechamentos)\n",
    "\n",
    "# Cubo intraday\n",
    "datahora = Get_data(tickers,'2018-01-01-10-00','2020-08-10-17-00','15m').reset_index()['Date']\n",
    "\n",
    "cubo_intraday = pd.DataFrame(columns=['data','periodo','ratio','adf_stat','adf_sign','coef_Ang',\n",
    "                                         'desvio','pct_fin','meia_vida', 'corr'])\n",
    "\n",
    "for dthora in datahora:\n",
    "    \n",
    "    # Convertendo 2018-01-02 10:30 para 2018-01-02-10-30\n",
    "    dthora1 = dthora.split(' ')\n",
    "    dthora2 = dthora1[0]+\"-\"+dthora1[1]\n",
    "    dthora1 = dthora2.split(':')\n",
    "    dthora2 = dthora1[0]+\"-\"+dthora1[1]\n",
    "    print(dthora2)\n",
    "    tmp = Get_Cubo(tickers,str(dthora2),True)\n",
    "    tmp['data']=str(dthora2)\n",
    "    cubo_intraday = cubo_intraday.append(tmp)\n",
    "\n",
    "print(cubo_intraday)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
